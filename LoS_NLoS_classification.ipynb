{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b980fb99",
   "metadata": {},
   "source": [
    "## Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d18ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io \n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606c205",
   "metadata": {},
   "source": [
    "## Dataset Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dca00",
   "metadata": {},
   "source": [
    "### Read in the original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c7763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_origin = torch.load('Dataset/train_dl.pt')\n",
    "valid_dl_origin = torch.load('Dataset/valid_dl.pt')\n",
    "\n",
    "train_CSI = train_dl_origin.dataset[:][0]\n",
    "train_label = train_dl_origin.dataset[:][1][:,2].type(torch.LongTensor)\n",
    "\n",
    "valid_CSI = valid_dl_origin.dataset[:][0]\n",
    "valid_label = valid_dl_origin.dataset[:][1][:,2].type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c1e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee997e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000])\n"
     ]
    }
   ],
   "source": [
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7566af9",
   "metadata": {},
   "source": [
    "### CSI Processing: Take Modulus of complex matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91b91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CSI_modulus = torch.abs(train_CSI)\n",
    "valid_CSI_modulus = torch.abs(valid_CSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fb12a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[100.6578, 124.7878, 106.1179,  ..., 304.7704, 299.6064, 324.3594],\n",
      "          [132.8157, 106.6771,  91.2688,  ..., 269.1561, 323.5568, 299.9617],\n",
      "          [129.1395, 148.4756, 170.0735,  ..., 399.8112, 407.4420, 402.0112],\n",
      "          [ 74.0000,  71.4493,  59.3633,  ..., 134.0149, 129.6919, 124.0363]]],\n",
      "\n",
      "\n",
      "        [[[177.0198, 170.4963, 169.1065,  ...,  46.6154,  37.6431,  64.4981],\n",
      "          [143.6802, 143.0874,  88.0909,  ...,  44.0454,  22.2036,  27.6586],\n",
      "          [ 97.8008,  80.7527,  71.7008,  ...,  32.2025,  22.4722,  39.3573],\n",
      "          [ 39.8121,  45.7930,  31.6228,  ...,  16.5529,   8.0623,  25.6125]]],\n",
      "\n",
      "\n",
      "        [[[411.3940, 421.5412, 380.1276,  ..., 509.8431, 550.0582, 539.8120],\n",
      "          [366.8079, 387.3629, 353.0340,  ..., 596.1241, 619.6975, 605.5353],\n",
      "          [574.8991, 593.8560, 612.0008,  ..., 928.9521, 923.3618, 914.0552],\n",
      "          [289.8362, 287.2368, 281.0427,  ..., 354.9113, 339.0634, 333.9461]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[296.5889, 288.2672, 292.7695,  ..., 388.4289, 365.5380, 326.5287],\n",
      "          [273.3862, 265.4525, 250.9283,  ..., 330.0682, 296.2735, 331.4845],\n",
      "          [176.4795, 186.6039, 184.8161,  ..., 353.2775, 364.3350, 341.8786],\n",
      "          [ 90.3770,  88.4138, 101.9510,  ..., 153.5838, 164.6390, 143.2096]]],\n",
      "\n",
      "\n",
      "        [[[316.8359, 295.8463, 308.2872,  ..., 268.6001, 285.3086, 291.7602],\n",
      "          [240.7094, 218.8744, 216.6887,  ..., 127.0118, 118.3427, 114.0044],\n",
      "          [158.0506, 149.5761, 137.2443,  ...,  66.8506,  52.4976,  70.6045],\n",
      "          [119.0798, 103.5761, 110.1454,  ...,  85.7555,  70.0071,  75.8947]]],\n",
      "\n",
      "\n",
      "        [[[ 80.6102,  84.8528,  80.0625,  ..., 321.7111, 336.7566, 329.2567],\n",
      "          [ 55.4437,  73.0616, 118.0381,  ..., 272.0294, 295.6772, 295.6772],\n",
      "          [ 97.9898, 130.2306, 116.2755,  ..., 316.7649, 289.8034, 316.6591],\n",
      "          [104.1777, 115.9353, 104.4031,  ..., 116.6619, 135.9779, 111.5213]]]])\n"
     ]
    }
   ],
   "source": [
    "print(train_CSI_modulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "631db329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 1, 4, 1632])\n",
      "torch.Size([5000, 1, 4, 1632])\n"
     ]
    }
   ],
   "source": [
    "print(train_CSI_modulus.shape)\n",
    "print(valid_CSI_modulus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9fa7c",
   "metadata": {},
   "source": [
    "###  CSI Processing: Normalize to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0564be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling\n",
    "min_value = torch.min(train_CSI_modulus)\n",
    "max_value = torch.max(train_CSI_modulus)\n",
    "\n",
    "normalized_train_CSI_modulus = (train_CSI_modulus - min_value) / (max_value - min_value)\n",
    "normalized_valid_CSI_modulus = (valid_CSI_modulus - min_value) / (max_value - min_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3807eb1",
   "metadata": {},
   "source": [
    "### ML Classifcation w/ KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4ad6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 4d to 2d\n",
    "train_data_2d = normalized_train_CSI_modulus.view(normalized_train_CSI_modulus.size(0), -1)  # Reshape to (15000, 4 * 1632)\n",
    "valid_data_2d = normalized_valid_CSI_modulus.view(normalized_valid_CSI_modulus.size(0), -1)  # Reshape to (15000, 4 * 1632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split \n",
    "x, y = np.array(train_data_2d), np.array(train_label)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of KNN classifier on training set: 0.83\n",
      "Mean accuracy of KNN classifier on validation set: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "sq = int(np.sqrt(15000))\n",
    "knn = KNeighborsClassifier(n_neighbors=sq - 35)\n",
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "for train_index, valid_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "\n",
    "    knn.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    train_score = knn.score(X_train_fold, y_train_fold)\n",
    "    valid_score = knn.score(X_valid_fold, y_valid_fold)\n",
    "\n",
    "    train_scores.append(train_score)\n",
    "    valid_scores.append(valid_score)\n",
    "\n",
    "mean_train_score = np.mean(train_scores)\n",
    "mean_valid_score = np.mean(valid_scores)\n",
    "\n",
    "print('Mean accuracy of KNN classifier on training set: {:.2f}'.format(mean_train_score))\n",
    "print('Mean accuracy of KNN classifier on validation set: {:.2f}'.format(mean_valid_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f050050",
   "metadata": {},
   "source": [
    "### ANN approach (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8634c1b",
   "metadata": {},
   "source": [
    "- Instantiate a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "692a9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Linear(in_features=6528, out_features=50, bias=True)\n",
      "  (layer2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (layer3): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (layer4): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(4*1632, 50)  # input layer (4*1632 nodes) -> hidden layer (50 nodes)\n",
    "        self.layer2 = nn.Linear(50, 50)  # hidden layer (50 nodes) -> hidden layer (50 nodes)\n",
    "        self.layer3 = nn.Linear(50, 100)  # hidden layer (50 nodes) -> hidden layer (100 nodes)\n",
    "        self.layer4 = nn.Linear(100, 1)  # hidden layer (100 nodes) -> output layer (1 nodes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer4(F.relu(self.layer3(F.relu(self.layer2(F.relu(self.layer1(x)))))))\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82a460",
   "metadata": {},
   "source": [
    "- Add a loss function and an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "064e0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # define the loss function\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)  # define the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a740b5",
   "metadata": {},
   "source": [
    "- Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f694136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joey\\AppData\\Local\\Temp\\ipykernel_10040\\3324997130.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data_2d = torch.tensor(train_data_2d, dtype=torch.float32)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Temp\\ipykernel_10040\\3324997130.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_label = torch.tensor(train_label, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7042821645736694\n",
      "Epoch [2/100], Loss: 0.7035064697265625\n",
      "Epoch [3/100], Loss: 0.702040433883667\n",
      "Epoch [4/100], Loss: 0.6999729871749878\n",
      "Epoch [5/100], Loss: 0.6973907351493835\n",
      "Epoch [6/100], Loss: 0.6943718194961548\n",
      "Epoch [7/100], Loss: 0.6909857988357544\n",
      "Epoch [8/100], Loss: 0.6873055696487427\n",
      "Epoch [9/100], Loss: 0.683409571647644\n",
      "Epoch [10/100], Loss: 0.6793515086174011\n",
      "Epoch [11/100], Loss: 0.675180196762085\n",
      "Epoch [12/100], Loss: 0.6709069013595581\n",
      "Epoch [13/100], Loss: 0.6665186285972595\n",
      "Epoch [14/100], Loss: 0.6620393395423889\n",
      "Epoch [15/100], Loss: 0.6575016975402832\n",
      "Epoch [16/100], Loss: 0.6529285311698914\n",
      "Epoch [17/100], Loss: 0.648339033126831\n",
      "Epoch [18/100], Loss: 0.6437436938285828\n",
      "Epoch [19/100], Loss: 0.6391444802284241\n",
      "Epoch [20/100], Loss: 0.6345362067222595\n",
      "Epoch [21/100], Loss: 0.6299110651016235\n",
      "Epoch [22/100], Loss: 0.6252683401107788\n",
      "Epoch [23/100], Loss: 0.6206141114234924\n",
      "Epoch [24/100], Loss: 0.6159577965736389\n",
      "Epoch [25/100], Loss: 0.6113020181655884\n",
      "Epoch [26/100], Loss: 0.606643795967102\n",
      "Epoch [27/100], Loss: 0.6019852757453918\n",
      "Epoch [28/100], Loss: 0.5973373055458069\n",
      "Epoch [29/100], Loss: 0.5927079319953918\n",
      "Epoch [30/100], Loss: 0.5881109833717346\n",
      "Epoch [31/100], Loss: 0.5835610628128052\n",
      "Epoch [32/100], Loss: 0.5790690779685974\n",
      "Epoch [33/100], Loss: 0.5746406316757202\n",
      "Epoch [34/100], Loss: 0.5702685713768005\n",
      "Epoch [35/100], Loss: 0.5659398436546326\n",
      "Epoch [36/100], Loss: 0.5616475343704224\n",
      "Epoch [37/100], Loss: 0.5573880672454834\n",
      "Epoch [38/100], Loss: 0.5531589984893799\n",
      "Epoch [39/100], Loss: 0.5489594340324402\n",
      "Epoch [40/100], Loss: 0.5447890758514404\n",
      "Epoch [41/100], Loss: 0.5406501889228821\n",
      "Epoch [42/100], Loss: 0.536542534828186\n",
      "Epoch [43/100], Loss: 0.5324639081954956\n",
      "Epoch [44/100], Loss: 0.5284105539321899\n",
      "Epoch [45/100], Loss: 0.5243804454803467\n",
      "Epoch [46/100], Loss: 0.5203726291656494\n",
      "Epoch [47/100], Loss: 0.5163871645927429\n",
      "Epoch [48/100], Loss: 0.5124291181564331\n",
      "Epoch [49/100], Loss: 0.5085048079490662\n",
      "Epoch [50/100], Loss: 0.5046190023422241\n",
      "Epoch [51/100], Loss: 0.5007745027542114\n",
      "Epoch [52/100], Loss: 0.49697378277778625\n",
      "Epoch [53/100], Loss: 0.4932212233543396\n",
      "Epoch [54/100], Loss: 0.48952415585517883\n",
      "Epoch [55/100], Loss: 0.48588985204696655\n",
      "Epoch [56/100], Loss: 0.4823269546031952\n",
      "Epoch [57/100], Loss: 0.47884276509284973\n",
      "Epoch [58/100], Loss: 0.4754446744918823\n",
      "Epoch [59/100], Loss: 0.47213879227638245\n",
      "Epoch [60/100], Loss: 0.46893224120140076\n",
      "Epoch [61/100], Loss: 0.465831458568573\n",
      "Epoch [62/100], Loss: 0.46284228563308716\n",
      "Epoch [63/100], Loss: 0.45997005701065063\n",
      "Epoch [64/100], Loss: 0.45722144842147827\n",
      "Epoch [65/100], Loss: 0.45460277795791626\n",
      "Epoch [66/100], Loss: 0.4521191120147705\n",
      "Epoch [67/100], Loss: 0.44977471232414246\n",
      "Epoch [68/100], Loss: 0.44757142663002014\n",
      "Epoch [69/100], Loss: 0.44551050662994385\n",
      "Epoch [70/100], Loss: 0.44359177350997925\n",
      "Epoch [71/100], Loss: 0.44181519746780396\n",
      "Epoch [72/100], Loss: 0.4401784837245941\n",
      "Epoch [73/100], Loss: 0.43867796659469604\n",
      "Epoch [74/100], Loss: 0.43731018900871277\n",
      "Epoch [75/100], Loss: 0.43607038259506226\n",
      "Epoch [76/100], Loss: 0.43495360016822815\n",
      "Epoch [77/100], Loss: 0.43395471572875977\n",
      "Epoch [78/100], Loss: 0.4330675005912781\n",
      "Epoch [79/100], Loss: 0.4322853982448578\n",
      "Epoch [80/100], Loss: 0.43160074949264526\n",
      "Epoch [81/100], Loss: 0.43100613355636597\n",
      "Epoch [82/100], Loss: 0.430494099855423\n",
      "Epoch [83/100], Loss: 0.43005719780921936\n",
      "Epoch [84/100], Loss: 0.4296875298023224\n",
      "Epoch [85/100], Loss: 0.4293774962425232\n",
      "Epoch [86/100], Loss: 0.42911994457244873\n",
      "Epoch [87/100], Loss: 0.42890849709510803\n",
      "Epoch [88/100], Loss: 0.42873644828796387\n",
      "Epoch [89/100], Loss: 0.42859792709350586\n",
      "Epoch [90/100], Loss: 0.42848727107048035\n",
      "Epoch [91/100], Loss: 0.42839956283569336\n",
      "Epoch [92/100], Loss: 0.42833054065704346\n",
      "Epoch [93/100], Loss: 0.4282759726047516\n",
      "Epoch [94/100], Loss: 0.42823249101638794\n",
      "Epoch [95/100], Loss: 0.42819732427597046\n",
      "Epoch [96/100], Loss: 0.4281679093837738\n",
      "Epoch [97/100], Loss: 0.42814233899116516\n",
      "Epoch [98/100], Loss: 0.42811891436576843\n",
      "Epoch [99/100], Loss: 0.42809629440307617\n",
      "Epoch [100/100], Loss: 0.4280734956264496\n"
     ]
    }
   ],
   "source": [
    "train_data_2d = torch.tensor(train_data_2d, dtype=torch.float32)\n",
    "train_label = torch.tensor(train_label, dtype=torch.float32)\n",
    "train_label = train_label.view(-1, 1)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(train_data_2d)\n",
    "    loss = criterion(output, train_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417d900",
   "metadata": {},
   "source": [
    "- Test the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64a1bc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.28%\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_predictions = model(test_data)\n",
    "\n",
    "    rounded_predictions = torch.round(torch.sigmoid(test_predictions))\n",
    "    accuracy = accuracy_score(test_labels, rounded_predictions)\n",
    "    return accuracy\n",
    "\n",
    "accuracy = test_accuracy(net, valid_data_2d, valid_label)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
