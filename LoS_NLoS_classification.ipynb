{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b980fb99",
   "metadata": {},
   "source": [
    "## Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d18ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io \n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606c205",
   "metadata": {},
   "source": [
    "## Dataset Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dca00",
   "metadata": {},
   "source": [
    "### Read in the original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c7763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_origin = torch.load('Dataset/train_dl.pt')\n",
    "valid_dl_origin = torch.load('Dataset/valid_dl.pt')\n",
    "\n",
    "train_CSI = train_dl_origin.dataset[:][0]\n",
    "train_label = train_dl_origin.dataset[:][1][:,2].type(torch.LongTensor)\n",
    "\n",
    "valid_CSI = valid_dl_origin.dataset[:][0]\n",
    "valid_label = valid_dl_origin.dataset[:][1][:,2].type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c1e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee997e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000])\n"
     ]
    }
   ],
   "source": [
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7566af9",
   "metadata": {},
   "source": [
    "### CSI Processing: Take Modulus of complex matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91b91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CSI_modulus = torch.abs(train_CSI)\n",
    "valid_CSI_modulus = torch.abs(valid_CSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb12a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[100.6578, 124.7878, 106.1179,  ..., 304.7704, 299.6064, 324.3594],\n",
      "          [132.8157, 106.6771,  91.2688,  ..., 269.1561, 323.5568, 299.9617],\n",
      "          [129.1395, 148.4756, 170.0735,  ..., 399.8112, 407.4420, 402.0112],\n",
      "          [ 74.0000,  71.4493,  59.3633,  ..., 134.0149, 129.6919, 124.0363]]],\n",
      "\n",
      "\n",
      "        [[[177.0198, 170.4963, 169.1065,  ...,  46.6154,  37.6431,  64.4981],\n",
      "          [143.6802, 143.0874,  88.0909,  ...,  44.0454,  22.2036,  27.6586],\n",
      "          [ 97.8008,  80.7527,  71.7008,  ...,  32.2025,  22.4722,  39.3573],\n",
      "          [ 39.8121,  45.7930,  31.6228,  ...,  16.5529,   8.0623,  25.6125]]],\n",
      "\n",
      "\n",
      "        [[[411.3940, 421.5412, 380.1276,  ..., 509.8431, 550.0582, 539.8120],\n",
      "          [366.8079, 387.3629, 353.0340,  ..., 596.1241, 619.6975, 605.5353],\n",
      "          [574.8991, 593.8560, 612.0008,  ..., 928.9521, 923.3618, 914.0552],\n",
      "          [289.8362, 287.2368, 281.0427,  ..., 354.9113, 339.0634, 333.9461]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[296.5889, 288.2672, 292.7695,  ..., 388.4289, 365.5380, 326.5287],\n",
      "          [273.3862, 265.4525, 250.9283,  ..., 330.0682, 296.2735, 331.4845],\n",
      "          [176.4795, 186.6039, 184.8161,  ..., 353.2775, 364.3350, 341.8786],\n",
      "          [ 90.3770,  88.4138, 101.9510,  ..., 153.5838, 164.6390, 143.2096]]],\n",
      "\n",
      "\n",
      "        [[[316.8359, 295.8463, 308.2872,  ..., 268.6001, 285.3086, 291.7602],\n",
      "          [240.7094, 218.8744, 216.6887,  ..., 127.0118, 118.3427, 114.0044],\n",
      "          [158.0506, 149.5761, 137.2443,  ...,  66.8506,  52.4976,  70.6045],\n",
      "          [119.0798, 103.5761, 110.1454,  ...,  85.7555,  70.0071,  75.8947]]],\n",
      "\n",
      "\n",
      "        [[[ 80.6102,  84.8528,  80.0625,  ..., 321.7111, 336.7566, 329.2567],\n",
      "          [ 55.4437,  73.0616, 118.0381,  ..., 272.0294, 295.6772, 295.6772],\n",
      "          [ 97.9898, 130.2306, 116.2755,  ..., 316.7649, 289.8034, 316.6591],\n",
      "          [104.1777, 115.9353, 104.4031,  ..., 116.6619, 135.9779, 111.5213]]]])\n"
     ]
    }
   ],
   "source": [
    "print(train_CSI_modulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631db329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 1, 4, 1632])\n",
      "torch.Size([5000, 1, 4, 1632])\n"
     ]
    }
   ],
   "source": [
    "print(train_CSI_modulus.shape)\n",
    "print(valid_CSI_modulus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9fa7c",
   "metadata": {},
   "source": [
    "###  CSI Processing: Normalize to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0564be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling\n",
    "min_value = torch.min(train_CSI_modulus)\n",
    "max_value = torch.max(train_CSI_modulus)\n",
    "\n",
    "normalized_train_CSI_modulus = (train_CSI_modulus - min_value) / (max_value - min_value)\n",
    "normalized_valid_CSI_modulus = (valid_CSI_modulus - min_value) / (max_value - min_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3807eb1",
   "metadata": {},
   "source": [
    "### ML Classifcation w/ KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ad6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 4d to 2d\n",
    "train_data_2d = normalized_train_CSI_modulus.view(normalized_train_CSI_modulus.size(0), -1)  # Reshape to (15000, 4 * 1632)\n",
    "valid_data_2d = normalized_valid_CSI_modulus.view(normalized_valid_CSI_modulus.size(0), -1)  # Reshape to (15000, 4 * 1632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split \n",
    "x, y = np.array(train_data_2d), np.array(train_label)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of KNN classifier on training set: 0.96\n",
      "Mean accuracy of KNN classifier on validation set: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "sq = int(np.sqrt(15000))\n",
    "knn = KNeighborsClassifier(n_neighbors=35)\n",
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "for train_index, valid_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "\n",
    "    knn.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    train_score = knn.score(X_train_fold, y_train_fold)\n",
    "    valid_score = knn.score(X_valid_fold, y_valid_fold)\n",
    "\n",
    "    train_scores.append(train_score)\n",
    "    valid_scores.append(valid_score)\n",
    "\n",
    "mean_train_score = np.mean(train_scores)\n",
    "mean_valid_score = np.mean(valid_scores)\n",
    "\n",
    "print('Mean accuracy of KNN classifier on training set: {:.2f}'.format(mean_train_score))\n",
    "print('Mean accuracy of KNN classifier on validation set: {:.2f}'.format(mean_valid_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f050050",
   "metadata": {},
   "source": [
    "### ANN approach (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on:  cpu\n"
     ]
    }
   ],
   "source": [
    "my_device = None\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.backends.mps.is_built()\n",
    "    my_device = torch.device(\"mps\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "print(\"Running on: \",my_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8634c1b",
   "metadata": {},
   "source": [
    "- Instantiate a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "692a9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(4 * 1632, 2048)\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        \n",
    "        self.layer2 = nn.Linear(2048, 2048)\n",
    "        self.bn2 = nn.BatchNorm1d(2048)\n",
    "        \n",
    "        self.layer3 = nn.Linear(2048, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.layer4 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.layer5 = nn.Linear(512, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.layer6 = nn.Linear(256, 64)\n",
    "        self.bn6 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.layer7 = nn.Linear(64, 32)\n",
    "        self.bn7 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.layer8 = nn.Linear(32, 16)\n",
    "        self.bn8 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.layer9 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.layer1(x)))\n",
    "        x = F.relu(self.bn2(self.layer2(x)))\n",
    "        x = F.relu(self.bn3(self.layer3(x)))\n",
    "        x = F.relu(self.bn4(self.layer4(x)))\n",
    "        x = F.relu(self.bn5(self.layer5(x)))\n",
    "        x = F.relu(self.bn6(self.layer6(x)))\n",
    "        x = F.relu(self.bn7(self.layer7(x)))\n",
    "        x = F.relu(self.bn8(self.layer8(x)))\n",
    "        x = self.layer9(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82a460",
   "metadata": {},
   "source": [
    "- Add a loss function and an optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a740b5",
   "metadata": {},
   "source": [
    "- Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f694136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 1.8078\n",
      "Epoch 2/50, Training Loss: 1.0102\n",
      "Epoch 3/50, Training Loss: 0.5564\n",
      "Epoch 4/50, Training Loss: 0.4867\n",
      "Epoch 5/50, Training Loss: 0.4334\n",
      "Epoch 6/50, Training Loss: 0.3068\n",
      "Epoch 7/50, Training Loss: 0.2564\n",
      "Epoch 8/50, Training Loss: 0.2255\n",
      "Epoch 9/50, Training Loss: 0.2056\n",
      "Epoch 10/50, Training Loss: 0.1915\n",
      "Epoch 11/50, Training Loss: 0.1830\n",
      "Epoch 12/50, Training Loss: 0.1716\n",
      "Epoch 13/50, Training Loss: 0.1662\n",
      "Epoch 14/50, Training Loss: 0.1615\n",
      "Epoch 15/50, Training Loss: 0.1571\n",
      "Epoch 16/50, Training Loss: 0.1531\n",
      "Epoch 17/50, Training Loss: 0.1511\n",
      "Epoch 18/50, Training Loss: 0.1493\n",
      "Epoch 19/50, Training Loss: 0.1475\n",
      "Epoch 20/50, Training Loss: 0.1457\n",
      "Epoch 21/50, Training Loss: 0.1440\n",
      "Epoch 22/50, Training Loss: 0.1431\n",
      "Epoch 23/50, Training Loss: 0.1423\n",
      "Epoch 24/50, Training Loss: 0.1415\n",
      "Epoch 25/50, Training Loss: 0.1407\n",
      "Epoch 26/50, Training Loss: 0.1399\n",
      "Epoch 27/50, Training Loss: 0.1395\n",
      "Epoch 28/50, Training Loss: 0.1391\n",
      "Epoch 29/50, Training Loss: 0.1387\n",
      "Epoch 30/50, Training Loss: 0.1383\n",
      "Epoch 31/50, Training Loss: 0.1379\n",
      "Epoch 32/50, Training Loss: 0.1377\n",
      "Epoch 33/50, Training Loss: 0.1376\n",
      "Epoch 34/50, Training Loss: 0.1374\n",
      "Epoch 35/50, Training Loss: 0.1372\n",
      "Epoch 36/50, Training Loss: 0.1370\n",
      "Epoch 37/50, Training Loss: 0.1369\n",
      "Epoch 38/50, Training Loss: 0.1368\n",
      "Epoch 39/50, Training Loss: 0.1367\n",
      "Epoch 40/50, Training Loss: 0.1366\n",
      "Epoch 41/50, Training Loss: 0.1365\n",
      "Epoch 42/50, Training Loss: 0.1365\n",
      "Epoch 43/50, Training Loss: 0.1364\n",
      "Epoch 44/50, Training Loss: 0.1364\n",
      "Epoch 45/50, Training Loss: 0.1363\n",
      "Epoch 46/50, Training Loss: 0.1363\n",
      "Epoch 47/50, Training Loss: 0.1363\n",
      "Epoch 48/50, Training Loss: 0.1362\n",
      "Epoch 49/50, Training Loss: 0.1362\n",
      "Epoch 50/50, Training Loss: 0.1362\n",
      "Epoch 1/50, Training Loss: 1.8694\n",
      "Epoch 2/50, Training Loss: 1.0105\n",
      "Epoch 3/50, Training Loss: 0.5673\n",
      "Epoch 4/50, Training Loss: 0.4193\n",
      "Epoch 5/50, Training Loss: 0.2778\n",
      "Epoch 6/50, Training Loss: 0.2218\n",
      "Epoch 7/50, Training Loss: 0.1999\n",
      "Epoch 8/50, Training Loss: 0.1865\n",
      "Epoch 9/50, Training Loss: 0.1759\n",
      "Epoch 10/50, Training Loss: 0.1668\n",
      "Epoch 11/50, Training Loss: 0.1588\n",
      "Epoch 12/50, Training Loss: 0.1552\n",
      "Epoch 13/50, Training Loss: 0.1517\n",
      "Epoch 14/50, Training Loss: 0.1484\n",
      "Epoch 15/50, Training Loss: 0.1453\n",
      "Epoch 16/50, Training Loss: 0.1423\n",
      "Epoch 17/50, Training Loss: 0.1409\n",
      "Epoch 18/50, Training Loss: 0.1395\n",
      "Epoch 19/50, Training Loss: 0.1381\n",
      "Epoch 20/50, Training Loss: 0.1367\n",
      "Epoch 21/50, Training Loss: 0.1354\n",
      "Epoch 22/50, Training Loss: 0.1347\n",
      "Epoch 23/50, Training Loss: 0.1341\n",
      "Epoch 24/50, Training Loss: 0.1334\n",
      "Epoch 25/50, Training Loss: 0.1328\n",
      "Epoch 26/50, Training Loss: 0.1321\n",
      "Epoch 27/50, Training Loss: 0.1318\n",
      "Epoch 28/50, Training Loss: 0.1315\n",
      "Epoch 29/50, Training Loss: 0.1312\n",
      "Epoch 30/50, Training Loss: 0.1309\n",
      "Epoch 31/50, Training Loss: 0.1306\n",
      "Epoch 32/50, Training Loss: 0.1304\n",
      "Epoch 33/50, Training Loss: 0.1303\n",
      "Epoch 34/50, Training Loss: 0.1301\n",
      "Epoch 35/50, Training Loss: 0.1300\n",
      "Epoch 36/50, Training Loss: 0.1298\n",
      "Epoch 37/50, Training Loss: 0.1297\n",
      "Epoch 38/50, Training Loss: 0.1297\n",
      "Epoch 39/50, Training Loss: 0.1296\n",
      "Epoch 40/50, Training Loss: 0.1295\n",
      "Epoch 41/50, Training Loss: 0.1294\n",
      "Epoch 42/50, Training Loss: 0.1294\n",
      "Epoch 43/50, Training Loss: 0.1294\n",
      "Epoch 44/50, Training Loss: 0.1293\n",
      "Epoch 45/50, Training Loss: 0.1293\n",
      "Epoch 46/50, Training Loss: 0.1292\n",
      "Epoch 47/50, Training Loss: 0.1292\n",
      "Epoch 48/50, Training Loss: 0.1292\n",
      "Epoch 49/50, Training Loss: 0.1292\n",
      "Epoch 50/50, Training Loss: 0.1292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import copy\n",
    "from sklearn.model_selection import KFold  \n",
    "import torch.nn.init as init\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "\n",
    "num_folds = 2\n",
    "kf = KFold(n_splits=num_folds)\n",
    "best_model_states = []\n",
    "best_losses = []\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for train_index, valid_index in kf.split(train_data_2d):\n",
    "    # Split the data into training and validation sets for each fold\n",
    "    X_train_fold, X_valid_fold = train_data_2d[train_index], train_data_2d[valid_index]\n",
    "    y_train_fold, y_valid_fold = train_label[train_index], train_label[valid_index]\n",
    "\n",
    "    net = Net() \n",
    "     \n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.08)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_loss = float('inf')  \n",
    "    best_model_state_dict = None\n",
    "\n",
    "    num_epochs = 50\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(X_train_fold)\n",
    "        loss = criterion(output, y_train_fold)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print('Epoch %d/%d, Training Loss: %.4f' % (epoch+1, num_epochs, loss.item()))\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model_state_dict = copy.deepcopy(net.state_dict())\n",
    "\n",
    "    best_model_states.append(best_model_state_dict)\n",
    "    best_losses.append(best_loss)\n",
    "\n",
    "best_fold = best_losses.index(min(best_losses))\n",
    "best_model_state_dict = best_model_states[best_fold]\n",
    "net = Net()  # Initialize a new model\n",
    "net.load_state_dict(best_model_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9775333333333334\n",
      "Validation Accuracy: 0.9732\n",
      "Training R-squared: 0.8459987017145988\n",
      "Validation R-squared: 0.823865165892725\n",
      "Training MSE: 0.022466667\n",
      "Validation MSE: 0.0268\n",
      "Training MAE: 0.022466667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    train_predictions = net(train_data_2d)\n",
    "    test_predictions = net(valid_data_2d)\n",
    "\n",
    "# Apply sigmoid activation\n",
    "train_predictions = torch.sigmoid(train_predictions)\n",
    "test_predictions = torch.sigmoid(test_predictions)\n",
    "\n",
    "# Round to 0 or 1\n",
    "train_predictions = torch.round(train_predictions)\n",
    "test_predictions = torch.round(test_predictions)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(train_label, train_predictions.numpy()))\n",
    "print(\"Validation Accuracy:\", accuracy_score(valid_label, test_predictions.numpy()))\n",
    "print(\"Training R-squared:\", r2_score(train_label, train_predictions))\n",
    "print(\"Validation R-squared:\", r2_score(valid_label, test_predictions))\n",
    "print(\"Training MSE:\", mean_squared_error(train_label, train_predictions))\n",
    "print(\"Validation MSE:\", mean_squared_error(valid_label, test_predictions))\n",
    "print(\"Training MAE:\", mean_absolute_error(train_label, train_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
